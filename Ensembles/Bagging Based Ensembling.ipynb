{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i033085/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Use PrettyTensor to simplify Neural Network construction.\n",
    "import prettytensor as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was developed using Python 3.5.2 (Anaconda) and TensorFlow version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PrettyTensor version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.7.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "train_data = genfromtxt('optdigits.tra', delimiter=',')\n",
    "test_data = genfromtxt('optdigits.tes.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train = train_data[:, :-1].astype(np.float32)\n",
    "features_test = test_data[:, :-1].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_train = train_data[:, -1:].astype(int)\n",
    "labels_test =  test_data[:, -1:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onehot_labels_train = np.zeros((train_data.shape[0], 10))\n",
    "for i in range(train_data.shape[0]):\n",
    "    j = labels_train[i]\n",
    "    onehot_labels_train[i,j] = 1\n",
    "onehot_labels_test = np.zeros((test_data.shape[0], 10))\n",
    "for i in range(test_data.shape[0]):\n",
    "    j = labels_test[i]\n",
    "    onehot_labels_test[i,j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels_cls = np.argmax(onehot_labels_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t3823\n",
      "- Test-set:\t\t1797\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(train_data)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating random training-sets\n",
    "\n",
    "We will train 5 neural networks on different training-sets that are selected at random. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_images = features_train\n",
    "combined_labels = onehot_labels_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the shape of the combined arrays is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3823, 64)\n",
      "(3823, 10)\n"
     ]
    }
   ],
   "source": [
    "print(combined_images.shape)\n",
    "print(combined_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of the combined data-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3823"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_size = len(combined_images)\n",
    "combined_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the size of the training-set used for each neural network. You can try and change this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3440"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(0.9 * combined_size)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not use a validation-set during training, but this would be the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_size = combined_size - train_size\n",
    "validation_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper-function for splitting the combined data-set into a random training- and validation-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    # Create a randomized index into the full / combined training-set.\n",
    "    idx = np.random.permutation(combined_size)\n",
    "\n",
    "    # Split the random index into training- and validation-sets.\n",
    "    idx_train = idx[0:train_size]\n",
    "    idx_validation = idx[train_size:]\n",
    "\n",
    "    # Select the images and labels for the new training-set.\n",
    "    x_train = combined_images[idx_train, :]\n",
    "    y_train = combined_labels[idx_train, :]\n",
    "\n",
    "    # Select the images and labels for the new validation-set.\n",
    "    x_validation = combined_images[idx_validation, :]\n",
    "    y_validation = combined_labels[idx_validation, :]\n",
    "\n",
    "    # Return the new training- and validation-sets.\n",
    "    return x_train, y_train, x_validation, y_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data dimensions are used in several places in the source-code below. They are defined once so we can use these variables instead of numbers throughout the source-code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We know that MNIST images are 28 pixels in each dimension.\n",
    "img_size = 8\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function used to plot 9 images in a 3x3 grid, and writing the true and predicted classes below each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images,                  # Images to plot, 2-d array.\n",
    "                cls_true,                # True class-no for images.\n",
    "                ensemble_cls_pred=None,  # Ensemble predicted class-no.\n",
    "                best_cls_pred=None):     # Best-net predicted class-no.\n",
    "\n",
    "    assert len(images) == len(cls_true)\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    # Adjust vertical spacing if we need to print ensemble and best-net.\n",
    "    if ensemble_cls_pred is None:\n",
    "        hspace = 0.3\n",
    "    else:\n",
    "        hspace = 1.0\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=0.3)\n",
    "\n",
    "    # For each of the sub-plots.\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "\n",
    "        # There may not be enough images for all sub-plots.\n",
    "        if i < len(images):\n",
    "            # Plot image.\n",
    "            ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "            # Show true and predicted classes.\n",
    "            if ensemble_cls_pred is None:\n",
    "                xlabel = \"True: {0}\".format(cls_true[i])\n",
    "            else:\n",
    "                msg = \"True: {0}\\nEnsemble: {1}\\nBest Net: {2}\"\n",
    "                xlabel = msg.format(cls_true[i],\n",
    "                                    ensemble_cls_pred[i],\n",
    "                                    best_cls_pred[i])\n",
    "\n",
    "            # Show the classes as the label on the x-axis.\n",
    "            ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a few images to see if data is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAD5CAYAAABhwOHSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e0df750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the first images from the test-set.\n",
    "images = features_test[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = onehot_labels_test[0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-4674210f2acc>:1: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    }
   ],
   "source": [
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_pretty = pt.wrap(x_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/i033085/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From /Users/i033085/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/nn/python/ops/cross_entropy.py:68: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with pt.defaults_scope(activation_fn=tf.nn.relu):\n",
    "    y_pred, loss = x_pretty.\\\n",
    "        conv2d(kernel=3, depth=8, name='layer_conv1').\\\n",
    "        max_pool(kernel=2, stride=2).\\\n",
    "        conv2d(kernel=3, depth=16, name='layer_conv2').\\\n",
    "        max_pool(kernel=2, stride=2).\\\n",
    "        flatten().\\\n",
    "        fully_connected(size=256, name='layer_fc1').\\\n",
    "        softmax_classifier(num_classes=num_classes, labels=y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Measures\n",
    "\n",
    "We need a few more performance measures to display the progress to the user.\n",
    "\n",
    "First we calculate the predicted class number from the output of the neural network `y_pred`, which is a vector with 10 elements. The class number is the index of the largest element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification accuracy is calculated by first type-casting the vector of booleans to floats, so that False becomes 0 and True becomes 1, and then taking the average of these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(max_to_keep=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the directory used for saving and retrieving the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir = 'checkpoints/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the directory if it does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the save-path for the data-file with the given network number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_save_path(net_number):\n",
    "    return save_dir + 'network' + str(net_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TensorFlow session\n",
    "\n",
    "Once the TensorFlow graph has been created, we have to create a TensorFlow session which is used to execute the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables\n",
    "\n",
    "The variables for `weights` and `biases` must be initialized before we start optimizing them. We make a simple wrapper-function for this, because we will call it several times below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_variables():\n",
    "    session.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-function to create a random training batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for selecting a random training-batch of the given size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch(x_train, y_train):\n",
    "    # Total number of images in the training-set.\n",
    "    num_images = len(x_train)\n",
    "\n",
    "    # Create a random index into the training-set.\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=train_batch_size,\n",
    "                           replace=False)\n",
    "\n",
    "    # Use the random index to select random images and labels.\n",
    "    x_batch = x_train[idx, :]  # Images.\n",
    "    y_batch = y_train[idx, :]  # Labels.\n",
    "\n",
    "    # Return the batch.\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-function to perform optimization iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(num_iterations, x_train, y_train):\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        x_batch, y_true_batch = random_batch(x_train, y_train)\n",
    "\n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every 100 iterations and after last iteration.\n",
    "        if i % 100 == 0:\n",
    "\n",
    "            # Calculate the accuracy on the training-batch.\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # Status-message for printing.\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Batch Accuracy: {1:>6.1%}\"\n",
    "\n",
    "            # Print it.\n",
    "            print(msg.format(i + 1, acc))\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ensemble of neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of neural networks in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_networks = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of optimization iterations for each neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_iterations = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ensemble of neural networks. All networks use the same TensorFlow graph that was defined above. For each neural network the TensorFlow weights and variables are initialized to random values and then optimized. The variables are then saved to disk so they can be reloaded later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network: 0\n",
      "Optimization Iteration:      1, Training Batch Accuracy:  17.2%\n",
      "Optimization Iteration:    101, Training Batch Accuracy:  28.1%\n",
      "Optimization Iteration:    201, Training Batch Accuracy:  51.6%\n",
      "Optimization Iteration:    301, Training Batch Accuracy:  68.8%\n",
      "Optimization Iteration:    401, Training Batch Accuracy:  70.3%\n",
      "Optimization Iteration:    501, Training Batch Accuracy:  82.8%\n",
      "Optimization Iteration:    601, Training Batch Accuracy:  78.1%\n",
      "Optimization Iteration:    701, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:    801, Training Batch Accuracy:  89.1%\n",
      "Optimization Iteration:    901, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:   1001, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   1101, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   1201, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   1301, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1401, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   1501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1601, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:   1701, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1801, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1901, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2001, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   2101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2201, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2301, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2401, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2501, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   2601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2701, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3001, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3101, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3301, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3701, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9901, Training Batch Accuracy: 100.0%\n",
      "Time usage: 0:00:31\n",
      "()\n",
      "Neural network: 1\n",
      "Optimization Iteration:      1, Training Batch Accuracy:  10.9%\n",
      "Optimization Iteration:    101, Training Batch Accuracy:  23.4%\n",
      "Optimization Iteration:    201, Training Batch Accuracy:  50.0%\n",
      "Optimization Iteration:    301, Training Batch Accuracy:  57.8%\n",
      "Optimization Iteration:    401, Training Batch Accuracy:  78.1%\n",
      "Optimization Iteration:    501, Training Batch Accuracy:  84.4%\n",
      "Optimization Iteration:    601, Training Batch Accuracy:  85.9%\n",
      "Optimization Iteration:    701, Training Batch Accuracy:  85.9%\n",
      "Optimization Iteration:    801, Training Batch Accuracy:  84.4%\n",
      "Optimization Iteration:    901, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:   1001, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:   1101, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1201, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   1301, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:   1401, Training Batch Accuracy:  87.5%\n",
      "Optimization Iteration:   1501, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:   1601, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1701, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1801, Training Batch Accuracy:  89.1%\n",
      "Optimization Iteration:   1901, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2101, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   2201, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2401, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2701, Training Batch Accuracy:  96.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   2801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2901, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3201, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3301, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   3401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3901, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   4001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9901, Training Batch Accuracy: 100.0%\n",
      "Time usage: 0:00:43\n",
      "()\n",
      "Neural network: 2\n",
      "Optimization Iteration:      1, Training Batch Accuracy:   9.4%\n",
      "Optimization Iteration:    101, Training Batch Accuracy:  28.1%\n",
      "Optimization Iteration:    201, Training Batch Accuracy:  51.6%\n",
      "Optimization Iteration:    301, Training Batch Accuracy:  65.6%\n",
      "Optimization Iteration:    401, Training Batch Accuracy:  78.1%\n",
      "Optimization Iteration:    501, Training Batch Accuracy:  82.8%\n",
      "Optimization Iteration:    601, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:    701, Training Batch Accuracy:  73.4%\n",
      "Optimization Iteration:    801, Training Batch Accuracy:  84.4%\n",
      "Optimization Iteration:    901, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1001, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   1101, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:   1201, Training Batch Accuracy:  89.1%\n",
      "Optimization Iteration:   1301, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:   1401, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:   1501, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1601, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1701, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:   1801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1901, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   2001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2101, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   2201, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   2301, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:   2401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2601, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2701, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3001, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3101, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   3201, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3801, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4701, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   4801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5501, Training Batch Accuracy: 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   5601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6001, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   6101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9901, Training Batch Accuracy: 100.0%\n",
      "Time usage: 0:00:49\n",
      "()\n",
      "Neural network: 3\n",
      "Optimization Iteration:      1, Training Batch Accuracy:   4.7%\n",
      "Optimization Iteration:    101, Training Batch Accuracy:  31.2%\n",
      "Optimization Iteration:    201, Training Batch Accuracy:  54.7%\n",
      "Optimization Iteration:    301, Training Batch Accuracy:  70.3%\n",
      "Optimization Iteration:    401, Training Batch Accuracy:  75.0%\n",
      "Optimization Iteration:    501, Training Batch Accuracy:  85.9%\n",
      "Optimization Iteration:    601, Training Batch Accuracy:  87.5%\n",
      "Optimization Iteration:    701, Training Batch Accuracy:  89.1%\n",
      "Optimization Iteration:    801, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:    901, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:   1001, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:   1101, Training Batch Accuracy:  87.5%\n",
      "Optimization Iteration:   1201, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:   1301, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:   1401, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:   1501, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:   1601, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:   1701, Training Batch Accuracy:  87.5%\n",
      "Optimization Iteration:   1801, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:   1901, Training Batch Accuracy:  89.1%\n",
      "Optimization Iteration:   2001, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:   2101, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:   2201, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   2301, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2401, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:   2501, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:   2601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3001, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3201, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3301, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3501, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3801, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4301, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   4401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4801, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   4901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   8201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8301, Training Batch Accuracy: 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   8401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9901, Training Batch Accuracy: 100.0%\n",
      "Time usage: 0:00:51\n",
      "()\n",
      "Neural network: 4\n",
      "Optimization Iteration:      1, Training Batch Accuracy:   7.8%\n",
      "Optimization Iteration:    101, Training Batch Accuracy:  25.0%\n",
      "Optimization Iteration:    201, Training Batch Accuracy:  59.4%\n",
      "Optimization Iteration:    301, Training Batch Accuracy:  60.9%\n",
      "Optimization Iteration:    401, Training Batch Accuracy:  84.4%\n",
      "Optimization Iteration:    501, Training Batch Accuracy:  89.1%\n",
      "Optimization Iteration:    601, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:    701, Training Batch Accuracy:  85.9%\n",
      "Optimization Iteration:    801, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:    901, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   1001, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   1101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   1201, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   1301, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1401, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   1501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   1601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   1701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1801, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2101, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   2201, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2301, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   2401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3101, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3501, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   3601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9901, Training Batch Accuracy: 100.0%\n",
      "Time usage: 0:00:49\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    # For each of the neural networks.\n",
    "    for i in range(num_networks):\n",
    "        print(\"Neural network: {0}\".format(i))\n",
    "\n",
    "        # Create a random training-set. Ignore the validation-set.\n",
    "        x_train, y_train, _, _ = random_training_set()\n",
    "\n",
    "        # Initialize the variables of the TensorFlow graph.\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Optimize the variables using this training-set.\n",
    "        optimize(num_iterations=num_iterations,\n",
    "                 x_train=x_train,\n",
    "                 y_train=y_train)\n",
    "\n",
    "        # Save the optimized variables to disk.\n",
    "        saver.save(sess=session, save_path=get_save_path(i))\n",
    "\n",
    "        # Print newline.\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data-set in batches of this size to limit RAM usage.\n",
    "batch_size = 256\n",
    "\n",
    "def predict_labels(images):\n",
    "    # Number of images.\n",
    "    num_images = len(images)\n",
    "\n",
    "    # Allocate an array for the predicted labels which\n",
    "    # will be calculated in batches and filled into this array.\n",
    "    pred_labels = np.zeros(shape=(num_images, num_classes),\n",
    "                           dtype=np.float)\n",
    "\n",
    "    # Now calculate the predicted labels for the batches.\n",
    "    # We will just iterate through all the batches.\n",
    "    # There might be a more clever and Pythonic way of doing this.\n",
    "\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "\n",
    "    while i < num_images:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + batch_size, num_images)\n",
    "\n",
    "        # Create a feed-dict with the images between index i and j.\n",
    "        feed_dict = {x: images[i:j, :]}\n",
    "\n",
    "        # Calculate the predicted labels using TensorFlow.\n",
    "        pred_labels[i:j] = session.run(y_pred, feed_dict=feed_dict)\n",
    "\n",
    "        # Set the start-index for the next batch to the\n",
    "        # end-index of the current batch.\n",
    "        i = j\n",
    "\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate a boolean array whether the predicted classes for the images are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_prediction(images, labels, cls_true):\n",
    "    # Calculate the predicted labels.\n",
    "    pred_labels = predict_labels(images=images)\n",
    "\n",
    "    # Calculate the predicted class-number for each image.\n",
    "    cls_pred = np.argmax(pred_labels, axis=1)\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "    print(correct)\n",
    "\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate a boolean array whether the images in the test-set are classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_correct():\n",
    "    return correct_prediction(images = features_test,\n",
    "                              labels = onehot_labels_test,\n",
    "                              cls_true = test_labels_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate a boolean array whether the images in the validation-set are classified correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-functions for calculating the classification accuracy\n",
    "\n",
    "This function calculates the classification accuracy given a boolean array whether each image was correctly classified. E.g. `classification_accuracy([True, True, False, False, False]) = 2/5 = 0.4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_accuracy(correct):\n",
    "    # When averaging a boolean array, False means 0 and True means 1.\n",
    "    # So we are calculating: number of True / len(correct) which is\n",
    "    # the same as the classification accuracy.\n",
    "    return correct.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the classification accuracy on the test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_accuracy():\n",
    "    # Get the array of booleans whether the classifications are correct\n",
    "    # for the test-set.\n",
    "    correct = test_correct()\n",
    "    \n",
    "    # Calculate the classification accuracy and return it.\n",
    "    return classification_accuracy(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for calculating the predicted labels for all the neural networks in the ensemble. The labels are combined further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensemble_predictions():\n",
    "    # Empty list of predicted labels for each of the neural networks.\n",
    "    pred_labels = []\n",
    "\n",
    "    # Classification accuracy on the test-set for each network.\n",
    "    test_accuracies = []\n",
    "\n",
    "    \n",
    "\n",
    "    # For each neural network in the ensemble.\n",
    "    for i in range(num_networks):\n",
    "        # Reload the variables into the TensorFlow graph.\n",
    "        saver.restore(sess=session, save_path=get_save_path(i))\n",
    "\n",
    "        # Calculate the classification accuracy on the test-set.\n",
    "        test_acc = test_accuracy()\n",
    "        \n",
    "\n",
    "        # Append the classification accuracy to the list.\n",
    "        test_accuracies.append(test_acc)\n",
    "\n",
    "        # Print status message.\n",
    "        msg = \"Network: {0}, Accuracy on  Test-Set: {1:.4f}\"\n",
    "        print(msg.format(i, test_acc))\n",
    "\n",
    "        # Calculate the predicted labels for the images in the test-set.\n",
    "        # This is already calculated in test_accuracy() above but\n",
    "        # it is re-calculated here to keep the code a bit simpler.\n",
    "        pred = predict_labels(images=features_test)\n",
    "\n",
    "        # Append the predicted labels to the list.\n",
    "        pred_labels.append(pred)\n",
    "    \n",
    "    return np.array(pred_labels), \\\n",
    "           np.array(test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/network0\n",
      "[ True  True False ...  True  True  True]\n",
      "Network: 0, Accuracy on  Test-Set: 0.9416\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/network1\n",
      "[ True  True  True ...  True  True  True]\n",
      "Network: 1, Accuracy on  Test-Set: 0.9321\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/network2\n",
      "[ True  True False ...  True  True  True]\n",
      "Network: 2, Accuracy on  Test-Set: 0.9610\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/network3\n",
      "[ True  True  True ...  True  True  True]\n",
      "Network: 3, Accuracy on  Test-Set: 0.9494\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/network4\n",
      "[ True  True  True ...  True  True  True]\n",
      "Network: 4, Accuracy on  Test-Set: 0.9572\n"
     ]
    }
   ],
   "source": [
    "pred_labels, test_accuracies = ensemble_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the classification accuracies on the test-set for the neural networks in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test-set accuracy: 0.9482\n",
      "Min test-set accuracy:  0.9321\n",
      "Max test-set accuracy:  0.9610\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean test-set accuracy: {0:.4f}\".format(np.mean(test_accuracies)))\n",
    "print(\"Min test-set accuracy:  {0:.4f}\".format(np.min(test_accuracies)))\n",
    "print(\"Max test-set accuracy:  {0:.4f}\".format(np.max(test_accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted labels of the ensemble is a 3-dim array, the first dim is the network-number, the second dim is the image-number, the third dim is the classification vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1797, 10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_pred_labels = np.mean(pred_labels, axis=0)\n",
    "ensemble_pred_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble's predicted class number is then the index of the highest number in the label, which is calculated using argmax as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_cls_pred = np.argmax(ensemble_pred_labels, axis=1)\n",
    "ensemble_cls_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean array whether each of the images in the test-set was correctly classified by the ensemble of neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_correct = (ensemble_cls_pred == test_labels_cls)\n",
    "ensemble_correct.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negate the boolean array so we can use it to lookup incorrectly classified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_incorrect = np.logical_not(ensemble_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1741"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ensemble_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688369504730105"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.true_divide(np.sum(ensemble_correct),ensemble_correct.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best neural network\n",
    "\n",
    "Now we find the single neural network that performed best on the test-set.\n",
    "\n",
    "First list the classification accuracies on the test-set for all the neural networks in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94156928, 0.93210907, 0.96104619, 0.94936004, 0.95715081])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of the neural network with the highest classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_net = np.argmax(test_accuracies)\n",
    "best_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best neural network's classification accuracy on the test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9610461880912632"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracies[best_net]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted labels of the best neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_net_pred_labels = pred_labels[best_net, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted class-number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_net_cls_pred = np.argmax(best_net_pred_labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean array whether the best neural network classified each image in the test-set correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_net_correct = (best_net_cls_pred == test_labels_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean array whether each image is incorrectly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_net_incorrect = np.logical_not(best_net_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of ensemble vs. the best single network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of images in the test-set that were correctly classified by the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1741"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ensemble_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of images in the test-set that were correctly classified by the best neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1727"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(best_net_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean array whether each image in the test-set was correctly classified by the ensemble and incorrectly classified by the best neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_better = np.logical_and(best_net_incorrect,\n",
    "                                 ensemble_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of images in the test-set where the ensemble was better than the best single network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_better.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean array whether each image in the test-set was correctly classified by the best single network and incorrectly classified by the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_net_better = np.logical_and(best_net_correct,\n",
    "                                 ensemble_incorrect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of images in the test-set where the best single network was better than the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_net_better.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
