{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement  \n",
    "\n",
    "The goal is to forecast the demand for bikes in dependency of weather conditions like outside temperature and calendric informations e.g. holidays. These information and the demand structure is provided in a set with two years of daily historic data.  \n",
    "The demand is given as the total daily demand and as a split for registered users and casual users. To increase the quality of the prediction registered user demand and casual user demand will be predicted separately in step two.  \n",
    "To make predictions machine learning is used to train regressors. Scikit-Learn recommends a support vector regressor (SVR) for this kind of problem and data amount. In addition a deep neuronal network (DNN) regressor is trained for comparison. To find the hyper-parameters for these regressors grid search and randomized search are utilized. Due to the small dataset cross validation is applied.    \n",
    "\n",
    "> http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html  \n",
    "> http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR  \n",
    "> https://github.com/tensorflow/skflow/blob/master/g3doc/api_docs/python/estimators.md  \n",
    "> http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html  \n",
    "> http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read successfully!\n"
     ]
    }
   ],
   "source": [
    "# Fetching Dataset\n",
    "\n",
    "bike_data = pd.read_csv(\"day.csv\", header=0)\n",
    "\n",
    "print(\"Data read successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1        0        6           0   \n",
       "1        2  2011-01-02       1   0     1        0        0           0   \n",
       "2        3  2011-01-03       1   0     1        0        1           1   \n",
       "3        4  2011-01-04       1   0     1        0        2           1   \n",
       "4        5  2011-01-05       1   0     1        0        3           1   \n",
       "\n",
       "   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "\n",
       "    cnt  \n",
       "0   985  \n",
       "1   801  \n",
       "2  1349  \n",
       "3  1562  \n",
       "4  1600  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):\n",
      "Index(['instant', 'dteday', 'season', 'yr', 'mnth', 'holiday', 'weekday',\n",
      "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed'],\n",
      "      dtype='object')\n",
      "\n",
      "Target column:\n",
      "cnt\n"
     ]
    }
   ],
   "source": [
    "# Extracting\n",
    "\n",
    "feature_cols = bike_data.columns[:-3]  # all columns but last three are features\n",
    "target_col = bike_data.columns[-1]  # last column is the target\n",
    "\n",
    "print (\"Feature column(s):\\n{}\\n\".format(feature_cols))\n",
    "print (\"Target column:\\n{}\".format(target_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Calculate Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profit(y,y_cap):\n",
    "    return 3 * np.minimum(y[::1], y_cap[::1]) - 2 * y_cap[::1]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the base model the demand for today is the previous days demand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = bike_data[target_col][365:731]  # corresponding targets\n",
    "y_actual = y_actual.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_staged = y_actual.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data.insert(0, bike_data[target_col][364])\n",
    "data.insert(0, bike_data[target_col][363])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_df = pd.concat([pd.DataFrame(data), y_staged], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_df.drop(y_predicted_df.tail(2).index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = y_predicted_df[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate Base Model Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1442972\n"
     ]
    }
   ],
   "source": [
    "print(profit(y_actual,y_predicted).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms and Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demand as Target Variable - cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"processed_data_monthly_avg.csv\", header=0)\n",
    "data['instant'] = data['instant'] % 30\n",
    "X_raw_train = data[0:335]\n",
    "X_raw_test  = data[335:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instant', 'dteday', 'season', 'yr', 'mnth', 'holiday', 'weekday',\n",
       "       'workingday', 'weathersit', 'temp',\n",
       "       ...\n",
       "       'workingday__23', 'workingday__24', 'workingday__25', 'workingday__26',\n",
       "       'workingday__27', 'workingday__28', 'workingday__29',\n",
       "       'moving_avg_weekly_cnt', 'moving_avg_monthly_cnt', 'demand_pc_inc'],\n",
       "      dtype='object', length=338)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols =[\n",
    "       \"season__1\",\"season__2\",\"season__3\",\"season__4\",\"season__5\",\n",
    "       \"weathersit__1\",\"weathersit__2\",\"weathersit__3\",\"weathersit__4\",\"weathersit__5\",\n",
    "        \"atemp\",\"hum\",\"windspeed\",'cnt__1',\n",
    "        \"mnth\",\"instant\",\"holiday\",\"weekday\",\"workingday\",\n",
    "        \"moving_avg_weekly_cnt\"]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##New Set of Columns\n",
    "cols = [\n",
    "       'instant', 'season', 'yr', 'mnth', 'holiday', 'weekday','workingday', \n",
    "       'atemp__1', \n",
    "       'cnt__1', \n",
    "       'holiday__1',  \n",
    "       'hum__1', \n",
    "       'temp__1', \n",
    "       'weathersit__1',\n",
    "       'weekday__1',  \n",
    "       'windspeed__1',  \n",
    "       'workingday__1', \n",
    "       'moving_avg_weekly_cnt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_raw_train[cols].values.tolist()\n",
    "y_train_df = X_raw_train[['cnt']]\n",
    "y_train = y_train_df['cnt'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_raw_test[cols].values.tolist()\n",
    "y_test_df = X_raw_test[['cnt']]\n",
    "y_test = y_test_df['cnt'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cnt = data['cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_predictions = data_cnt[335:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_for_calculations = data_cnt[357:723].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training SVR\n",
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score SVR: -0.934610\n",
      "RMSE SVR: 2484.461417\n"
     ]
    }
   ],
   "source": [
    "# Validation SVR\n",
    "\n",
    "svr_pred = svr.predict(X_test)\n",
    "score_svr = r2_score(y_test, svr_pred)\n",
    "rmse_svr = sqrt(mean_squared_error(y_test, svr_pred))\n",
    "\n",
    "print(\"Score SVR: %f\" % score_svr)\n",
    "print(\"RMSE SVR: %f\" % rmse_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert demand to integer\n",
    "svr_pred=np.around(svr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1171674.0\n"
     ]
    }
   ],
   "source": [
    "print(profit(actual_predictions,svr_pred).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "The regressors are trained using randomized search and cross-validation to identify the area of the best parameters. Then a grid search is used to tune parameter values of the regressor functions.\n",
    "\n",
    "> http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html  \n",
    "> http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
      "       fit_params={}, iid=True, n_jobs=-1,\n",
      "       param_grid=[{'C': [1000, 3000, 10000], 'kernel': ['linear', 'rbf']}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring='r2', verbose=0)\n",
      "\n",
      "Best parameter from grid search: {'C': 10000, 'kernel': 'rbf'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tuning SVR with GridSearch\n",
    "\n",
    "tuned_parameters = [{'C': [1000, 3000, 10000], \n",
    "                     'kernel': ['linear','rbf']}\n",
    "                   ]\n",
    "\n",
    "#svr_tuned = GridSearchCV(SVR (C=1), param_grid = tuned_parameters, scoring = 'mean_squared_error') #default 3-fold cross-validation, score method of the estimator\n",
    "svr_tuned_GS = GridSearchCV(SVR (C=1), param_grid = tuned_parameters, scoring = 'r2', n_jobs=-1) #default 3-fold cross-validation, score method of the estimator\n",
    "\n",
    "svr_tuned_GS.fit(X_train, y_train)\n",
    "\n",
    "print (svr_tuned_GS)\n",
    "print ('\\n' \"Best parameter from grid search: \" + str(svr_tuned_GS.best_params_) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR Results\n",
      "\n",
      "Score SVR: -0.934610\n",
      "Score SVR tuned GS: -1.252493\n",
      "\n",
      "RMSE SVR: 2484.461417\n",
      "RMSE SVR tuned GS: 2680.818105\n"
     ]
    }
   ],
   "source": [
    "# Validation - SVR tuned \n",
    "\n",
    "svr_tuned_pred_GS = svr_tuned_GS.predict(X_test)\n",
    "\n",
    "score_svr_tuned_GS = r2_score(y_test, svr_tuned_pred_GS)\n",
    "rmse_svr_tuned_GS = sqrt(mean_squared_error(y_test, svr_tuned_pred_GS))\n",
    "\n",
    "print(\"SVR Results\\n\")\n",
    "\n",
    "print(\"Score SVR: %f\" % score_svr)\n",
    "print(\"Score SVR tuned GS: %f\" % score_svr_tuned_GS)\n",
    "\n",
    "print(\"\\nRMSE SVR: %f\" % rmse_svr)\n",
    "print(\"RMSE SVR tuned GS: %f\" % rmse_svr_tuned_GS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1123170.0\n"
     ]
    }
   ],
   "source": [
    "svr_tuned_pred_GS = np.around(svr_tuned_pred_GS)\n",
    "\n",
    "##Profit Calculation for cnt approach\n",
    "print(profit(actual_predictions,svr_tuned_pred_GS).sum())\n",
    "\n",
    "#Profit is just 1.08million!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best CV score from grid search: -1.528262\n",
      "corresponding parameters: {'C': 7396.351912361147, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# SVR tuned with RandomizesSearch\n",
    "# may take a while!\n",
    "\n",
    "# Parameters\n",
    "param_dist = {  'C': sp_uniform (1000, 10000), \n",
    "                'kernel': ['rbf']\n",
    "             }\n",
    "\n",
    "n_iter_search = 1\n",
    "\n",
    "# MSE optimized\n",
    "#SVR_tuned_RS = RandomizedSearchCV(SVR (C=1), param_distributions = param_dist, scoring = 'mean_squared_error', n_iter=n_iter_search)\n",
    "\n",
    "# R^2 optimized\n",
    "SVR_tuned_RS = RandomizedSearchCV(SVR (C=1), param_distributions = param_dist, scoring = 'r2', n_iter=n_iter_search)\n",
    "\n",
    "# Fit\n",
    "SVR_tuned_RS.fit(X_train, y_train)\n",
    "\n",
    "# Best score and corresponding parameters.\n",
    "print('best CV score from grid search: {0:f}'.format(SVR_tuned_RS.best_score_))\n",
    "print('corresponding parameters: {}'.format(SVR_tuned_RS.best_params_))\n",
    "\n",
    "# Predict and score\n",
    "predict = SVR_tuned_RS.predict(X_test)\n",
    "\n",
    "score_svr_tuned_RS = r2_score(y_test, predict)\n",
    "rmse_svr_tuned_RS = sqrt(mean_squared_error(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR Results\n",
      "\n",
      "Score SVR: -0.934610\n",
      "Score SVR tuned GS: -1.252493\n",
      "Score SVR tuned RS: -1.252493\n",
      "\n",
      "RMSE SVR: 2484.461417\n",
      "RMSE SVR tuned GS: 2680.818105\n",
      "RMSE SVR tuned RS: 2680.818105\n"
     ]
    }
   ],
   "source": [
    "print('SVR Results\\n')\n",
    "\n",
    "print(\"Score SVR: %f\" % score_svr)\n",
    "print(\"Score SVR tuned GS: %f\" % score_svr_tuned_GS)\n",
    "print(\"Score SVR tuned RS: %f\" % score_svr_tuned_RS)\n",
    "\n",
    "print(\"\\nRMSE SVR: %f\" % rmse_svr)\n",
    "print(\"RMSE SVR tuned GS: %f\" % rmse_svr_tuned_GS)\n",
    "print(\"RMSE SVR tuned RS: %f\" % rmse_svr_tuned_RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1123170.0\n"
     ]
    }
   ],
   "source": [
    "##Profit Calculation for cnt approach\n",
    "predict = np.around(predict)\n",
    "print(profit(actual_predictions,predict).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuning works for the SVR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, wait\n",
    "from time import time\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_model = MLPRegressor(hidden_layer_sizes=(5,),\n",
    "                                       activation='relu',\n",
    "                                       solver='adam',\n",
    "                                       learning_rate='adaptive',\n",
    "                                       max_iter=1000,\n",
    "                                       learning_rate_init=0.01,\n",
    "                                       alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = int(time() * 1000)\n",
    "bike_model.fit(X_train, y_train)\n",
    "end_time = int(time() * 1000)\n",
    "logging.debug('Finished training universal model')\n",
    "logging.debug('Training took {} ms'.format(end_time - start_time)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = bike_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = np.around(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1404788.0\n"
     ]
    }
   ],
   "source": [
    "print(profit(actual_predictions,predict).sum())\n",
    "#Profit is 1.52 million!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation metrics\n",
    "from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error # for regression\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score  # for classification\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor\n",
      "1378016.0\n",
      "GradientBoostingRegressor\n",
      "1340816.0\n",
      "AdaBoostRegressor\n",
      "1324388.0\n",
      "BaggingRegressor\n",
      "1171674.0\n",
      "SVR\n",
      "1337927.0\n"
     ]
    }
   ],
   "source": [
    "models=[RandomForestRegressor(),AdaBoostRegressor(),BaggingRegressor(),SVR(),KNeighborsRegressor()]\n",
    "model_names=['RandomForestRegressor','GradientBoostingRegressor','AdaBoostRegressor','BaggingRegressor','SVR','KNeighborsRegressor']\n",
    "rmsle=[]\n",
    "d={}\n",
    "for model in range (len(models)):\n",
    "    clf=models[model]\n",
    "    print(model_names[model])\n",
    "    clf.fit(X_train,y_train)\n",
    "    test_pred=clf.predict(X_test)\n",
    "    test_pred = np.around(test_pred)\n",
    "    print(profit(actual_predictions,test_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317369.0\n"
     ]
    }
   ],
   "source": [
    "#NOW LET'S Dig deeper into each of these ...\n",
    "#for random forest regresion.\n",
    "no_of_test=[500]\n",
    "params_dict={'n_estimators':no_of_test,'n_jobs':[-1],'max_features':[\"auto\",'sqrt','log2'],'max_depth':[10,20,30]}\n",
    "clf_rf=GridSearchCV(estimator=RandomForestRegressor(),param_grid=params_dict,scoring='neg_mean_squared_error')\n",
    "clf_rf.fit(X_train,y_train)\n",
    "pred=clf_rf.predict(X_test)\n",
    "#model_predictions = convertToPrediction(y_for_calculations,pred)\n",
    "pred=np.around(pred)\n",
    "print(profit(actual_predictions,pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'max_depth': 30, 'max_features': 'sqrt', 'n_estimators': 500, 'n_jobs': -1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params: \", clf_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1319910.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import pipeline,metrics,grid_search\n",
    "\n",
    "regressor = RandomForestRegressor(random_state = 0, max_depth = 40, n_estimators = 500, max_features = 'log2')\n",
    "estimator = pipeline.Pipeline(steps = [       \n",
    "    ('model_fitting', regressor)\n",
    "    ]\n",
    ")\n",
    "estimator.fit(X_train, y_train)\n",
    "test_pred = estimator.predict(X_test)\n",
    "test_pred = np.around(test_pred)\n",
    "print(profit(actual_predictions,test_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1954., 1749., 1886., 1815., 1980., 2122., 2132., 2436., 2601.,\n",
       "       2506., 2333., 2656., 2240., 2648., 2200., 2146., 1963., 1984.,\n",
       "       1976., 2050., 1899., 1938., 1737., 1838., 1987., 2251., 2399.,\n",
       "       2793., 2432., 2736., 2442., 3372., 2758., 2796., 2656., 2631.,\n",
       "       2410., 2492., 2544., 2716., 2441., 2542., 2617., 2299., 1993.,\n",
       "       2253., 2318., 2322., 2363., 2694., 2632., 2358., 2430., 3018.,\n",
       "       2831., 2638., 2478., 2405., 2518., 2636., 3467., 2479., 3096.,\n",
       "       2405., 2731., 2490., 2443., 3307., 2743., 2907., 2952., 3575.,\n",
       "       3541., 3625., 3628., 3003., 3492., 3371., 3531., 3466., 3351.,\n",
       "       3364., 3776., 3550., 3207., 3092., 3490., 4274., 4238., 3473.,\n",
       "       3465., 3755., 3898., 4481., 4524., 3907., 3674., 3960., 4544.,\n",
       "       4065., 4024., 3656., 3723., 3953., 4700., 4622., 4655., 4662.,\n",
       "       4093., 4412., 4415., 4510., 3097., 3292., 3238., 4013., 4169.,\n",
       "       3814., 3768., 4116., 4259., 4537., 4348., 4400., 4531., 4662.,\n",
       "       4543., 4439., 4343., 4353., 4397., 4628., 4972., 4699., 4234.,\n",
       "       4318., 4145., 4682., 4664., 5051., 4722., 4230., 4376., 4377.,\n",
       "       4599., 4609., 4714., 4596., 4609., 4446., 4593., 4825., 4453.,\n",
       "       4943., 4789., 4660., 4513., 4630., 4695., 4868., 5037., 4821.,\n",
       "       4714., 4194., 4399., 4738., 4742., 4984., 4754., 4245., 4604.,\n",
       "       4533., 4402., 4485., 4958., 4886., 4840., 4456., 4976., 4912.,\n",
       "       4470., 4888., 4650., 4757., 4749., 4685., 4546., 4575., 4457.,\n",
       "       4475., 4557., 4573., 4733., 4834., 5009., 4807., 4613., 4486.,\n",
       "       4510., 4472., 4555., 4178., 4148., 4505., 4353., 4520., 5016.,\n",
       "       4494., 4595., 4911., 4917., 4555., 4604., 4560., 4444., 4426.,\n",
       "       4595., 4460., 4478., 4519., 4491., 4617., 4447., 4659., 4918.,\n",
       "       4731., 4442., 4644., 4736., 3604., 4987., 4729., 4499., 4596.,\n",
       "       4803., 4885., 4995., 4641., 4262., 4628., 4721., 4811., 4881.,\n",
       "       4683., 4803., 4436., 4359., 4246., 4357., 4304., 4547., 4297.,\n",
       "       4646., 4608., 4689., 4590., 4661., 4602., 4807., 4818., 4365.,\n",
       "       3435., 4477., 4474., 4601., 4699., 4586., 4634., 4485., 4513.,\n",
       "       4496., 4498., 4497., 4558., 4506., 4010., 4376., 4258., 4495.,\n",
       "       4426., 3835., 3556., 3482., 4236., 3814., 3733., 3722., 4284.,\n",
       "       4099., 4240., 3814., 3951., 3996., 4477., 3822., 4481., 4533.,\n",
       "       4644., 4107., 4085., 4246., 3932., 2810., 3288., 3587., 3541.,\n",
       "       3510., 3418., 3446., 3409., 3475., 3307., 3252., 3491., 3794.,\n",
       "       3761., 4110., 3250., 3427., 3537., 3519., 3440., 3399., 3362.,\n",
       "       3605., 3526., 3576., 3571., 2904., 3492., 3668., 3317., 3498.,\n",
       "       3539., 3804., 3547., 3436., 3621., 3931., 3452., 3425., 3401.,\n",
       "       2832., 2677., 2630., 3422., 3366., 3406., 3483., 3608., 3323.,\n",
       "       2837., 3296., 3265., 3556., 3188., 3031., 3086., 2583., 2025.,\n",
       "       1730., 1894., 2144., 2067., 1948., 1933.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1324356.0\n"
     ]
    }
   ],
   "source": [
    "#for Gradient Boosting regresion.\n",
    "no_of_estimators=[100,200,300,400,500]\n",
    "params_dict={'n_estimators':no_of_estimators,'learning_rate':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "             'max_features':[\"auto\",'sqrt','log2'],'max_depth':[10,20,30,40,50]}\n",
    "clf_gbr=GridSearchCV(estimator=GradientBoostingRegressor(),param_grid=params_dict,scoring='neg_mean_squared_error')\n",
    "clf_gbr.fit(X_train,y_train)\n",
    "pred=clf_gbr.predict(X_test)\n",
    "pred=np.around(pred)\n",
    "print(profit(actual_predictions,pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'learning_rate': 0.1, 'max_depth': 40, 'max_features': 'sqrt', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params: \", clf_gbr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1306172.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators=300, learning_rate=0.1, max_depth = 20)\n",
    "\n",
    "estimator = pipeline.Pipeline(steps = [       \n",
    "    ('model_fitting', gbr)\n",
    "    ]\n",
    ")\n",
    "estimator.fit(X_train, y_train)\n",
    "test_pred = estimator.predict(X_test)\n",
    "test_pred = np.around(test_pred)\n",
    "print(profit(actual_predictions,test_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bagging Regressor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
